#!/usr/bin/env python3
"""
Unified PARA Notes Interface for Claude Code

A comprehensive slash command interface that integrates all PARA Method functionality
into a single, Claude Code-friendly command with JSON output and natural language support.
"""

import os
import re
import sys
import json
import argparse
import datetime
import subprocess
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict

# Import existing PARA tools
current_dir = Path(__file__).parent.absolute()
sys.path.insert(0, str(current_dir))

try:
    # Import from our existing modules using importlib for dash-named files
    import importlib.util

    # Load para-processor.py from scripts directory
    spec = importlib.util.spec_from_file_location("para_processor", "scripts/para-processor.py")
    para_processor_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(para_processor_module)

    # Load para-templates.py from root directory
    spec_templates = importlib.util.spec_from_file_location("para_templates", "para-templates.py")
    para_templates_module = importlib.util.module_from_spec(spec_templates)
    spec_templates.loader.exec_module(para_templates_module)

    # Extract the classes we need
    ParaNoteProcessor = para_processor_module.ParaNoteProcessor
    ParsedNote = para_processor_module.ParsedNote
    ActionItem = para_processor_module.ActionItem
    ParaCategory = para_processor_module.ParaCategory
    ParaTemplateEngine = para_templates_module.ParaTemplateEngine

    subprocess_mode = False
except Exception as e:
    # Fallback: execute as subprocess if modules can't be imported
    subprocess_mode = True
    ParaNoteProcessor = None
    ParsedNote = None
    ActionItem = None
    ParaCategory = None
    ParaTemplateEngine = None
    print(f"Warning: Could not import para modules ({e}), using subprocess mode")

@dataclass
class CommandResult:
    """Standardized result format for Claude Code integration"""
    success: bool
    command: str
    message: str
    data: Dict[str, Any] = None
    suggestions: List[str] = None
    error_details: str = None

class NotesCommandInterface:
    """Unified interface for all PARA Method note operations"""

    def __init__(self):
        if not subprocess_mode:
            self.processor = ParaNoteProcessor()
            self.template_engine = ParaTemplateEngine()
        else:
            self.processor = None
            self.template_engine = None

        # Natural language patterns for parameter extraction
        self.nl_patterns = {
            'attendees': [
                r'with\s+([^,\n]+(?:,\s*[^,\n]+)*)',
                r'attendees?\s*:?\s*([^,\n]+(?:,\s*[^,\n]+)*)',
                r'participants?\s*:?\s*([^,\n]+(?:,\s*[^,\n]+)*)'
            ],
            'topic': [
                r'about\s+"([^"]+)"',
                r'about\s+([^,\n]+)',
                r'topic\s*:?\s*"([^"]+)"',
                r'topic\s*:?\s*([^,\n]+)',
                r'regarding\s+([^,\n]+)',
                r'for\s+([^,\n]+)'
            ],
            'date': [
                r'on\s+(\d{4}-\d{2}-\d{2})',
                r'for\s+(\d{4}-\d{2}-\d{2})',
                r'date\s*:?\s*(\d{4}-\d{2}-\d{2})'
            ],
            'template': [
                r'using\s+(\w+)\s+template',
                r'template\s*:?\s*(\w+)',
                r'as\s+(?:a\s+)?(\w+)'
            ]
        }

    def extract_natural_language_params(self, text: str) -> Dict[str, str]:
        """Extract parameters from natural language text"""
        params = {}

        # Process in specific order to avoid overlaps
        # 1. Extract template first (most specific)
        for pattern in self.nl_patterns['template']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                value = match.group(1).strip()
                value = re.sub(r'^["\']|["\']$', '', value)
                params['template'] = value
                # Remove the template part to avoid interference with other patterns
                text = re.sub(pattern, '', text, flags=re.IGNORECASE)
                break

        # 2. Extract topic (before attendees to avoid overlap)
        for pattern in self.nl_patterns['topic']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                value = match.group(1).strip()
                value = re.sub(r'^["\']|["\']$', '', value)
                # Clean topic of attendee indicators
                value = re.sub(r'\s+with\s+.*$', '', value, flags=re.IGNORECASE)
                params['topic'] = value
                break

        # 3. Extract attendees (after removing template and cleaning topic)
        for pattern in self.nl_patterns['attendees']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                value = match.group(1).strip()
                value = re.sub(r'^["\']|["\']$', '', value)
                # Clean up template remnants and dates from attendees
                value = re.sub(r'\s+using\s+\w+\s+template.*$', '', value, flags=re.IGNORECASE)
                value = re.sub(r'\s+on\s+\d{4}-\d{2}-\d{2}.*$', '', value, flags=re.IGNORECASE)
                params['attendees'] = value
                break

        # 4. Extract date (least likely to interfere)
        for pattern in self.nl_patterns['date']:
            match = re.search(pattern, text, re.IGNORECASE)
            if match:
                value = match.group(1).strip()
                value = re.sub(r'^["\']|["\']$', '', value)
                params['date'] = value
                break

        return params

    def format_success_result(self, command: str, message: str, data: Dict[str, Any] = None,
                            suggestions: List[str] = None) -> CommandResult:
        """Format a successful command result"""
        return CommandResult(
            success=True,
            command=command,
            message=message,
            data=data or {},
            suggestions=suggestions or []
        )

    def format_error_result(self, command: str, message: str, error_details: str = None,
                          suggestions: List[str] = None) -> CommandResult:
        """Format an error command result"""
        return CommandResult(
            success=False,
            command=command,
            message=message,
            error_details=error_details,
            suggestions=suggestions or []
        )

    def cmd_capture(self, args) -> CommandResult:
        """Capture new notes using templates"""
        try:
            # Parse natural language if provided
            nl_params = {}
            if hasattr(args, 'natural') and args.natural:
                nl_params = self.extract_natural_language_params(' '.join(args.natural))

            # Determine template
            template = args.template or nl_params.get('template', 'quick-note')

            if not subprocess_mode and self.template_engine:
                # Use native method
                # Get template list for validation
                available_templates = self.template_engine.list_templates()
                all_templates = available_templates['built-in'] + available_templates['custom']

                if template not in all_templates:
                    return self.format_error_result(
                        'capture',
                        f"Template '{template}' not found",
                        suggestions=[f"Available templates: {', '.join(all_templates[:5])}"]
                    )

                # Prepare variables
                variables = {
                    'title': args.topic or nl_params.get('topic', 'New Note'),
                    'attendees': args.attendees or nl_params.get('attendees', ''),
                    'date': args.date or nl_params.get('date') or datetime.date.today().strftime('%Y-%m-%d')
                }

                # Add custom variables
                if args.var:
                    for var in args.var:
                        if '=' in var:
                            key, value = var.split('=', 1)
                            variables[key] = value

                # Create note
                output_path = self.template_engine.create_note(
                    template,
                    variables,
                    args.output
                )
            else:
                # Fallback to subprocess
                cmd = ['./para-templates.py', 'create', template]

                # Add variables as arguments
                title = args.topic or nl_params.get('topic', 'New Note')
                attendees = args.attendees or nl_params.get('attendees', '')
                date = args.date or nl_params.get('date') or datetime.date.today().strftime('%Y-%m-%d')

                cmd.extend(['--title', title])
                if attendees:
                    cmd.extend(['--attendees', attendees])

                if args.output:
                    cmd.extend(['--output', args.output])

                # Add date as a custom variable since para-templates.py doesn't have --date
                cmd.extend(['--var', f'date={date}'])

                # Add custom variables
                if args.var:
                    for var in args.var:
                        if '=' in var:
                            cmd.extend(['--var', var])

                result = subprocess.run(cmd, capture_output=True, text=True)

                if result.returncode != 0:
                    return self.format_error_result(
                        'capture',
                        f"Template creation failed: {result.stderr.strip()}",
                        result.stderr.strip()
                    )

                # Parse output to get the created file path
                output_lines = result.stdout.strip().split('\n')
                output_path = None
                for line in output_lines:
                    if 'Created note:' in line:
                        output_path = line.split('Created note:')[1].strip()
                        break

                if not output_path:
                    output_path = f"{template}-note.md"  # fallback

                variables = {'title': title, 'attendees': attendees, 'date': date}

            return self.format_success_result(
                'capture',
                f"Created note: {output_path}",
                {
                    'file_path': output_path,
                    'template': template,
                    'variables': variables
                },
                [f"Edit with: code {output_path}", f"Process with: /notes research --file {output_path}"]
            )

        except Exception as e:
            return self.format_error_result(
                'capture',
                f"Failed to create note: {str(e)}",
                str(e),
                ["Check template name and parameters", "Use /notes list-templates to see available templates"]
            )

    def cmd_process_inbox(self, args) -> CommandResult:
        """Process inbox notes with batch operations"""
        try:
            directory = args.directory or 'inbox'

            if not Path(directory).exists():
                return self.format_error_result(
                    'process-inbox',
                    f"Directory '{directory}' does not exist",
                    suggestions=["Create inbox directory first", "Use correct directory path"]
                )

            if not subprocess_mode and self.processor:
                # Use native method
                notes = self.processor.batch_process_notes(directory, args.pattern or '*.md')

                if not notes:
                    return self.format_success_result(
                        'process-inbox',
                        f"No notes found in {directory}",
                        {'notes_processed': 0, 'notes': []},
                        [f"Add notes to {directory} directory", "Check file pattern"]
                    )

                # Handle --list option: just return note summaries
                if getattr(args, 'list', False):
                    note_summaries = []
                    for note in notes:
                        note_summaries.append({
                            'id': str(Path(note.file_path).stem),
                            'file_path': note.file_path,
                            'title': note.frontmatter.get('title', Path(note.file_path).stem),
                            'word_count': note.word_count,
                            'action_items': len(note.action_items),
                            'suggested_category': note.suggested_category.value,
                            'preview': note.content[:200] + ('...' if len(note.content) > 200 else ''),
                            'tags': note.tags,
                            'created': note.frontmatter.get('created', 'unknown')
                        })

                    return self.format_success_result(
                        'process-inbox',
                        f"Found {len(note_summaries)} notes in {directory}",
                        {
                            'notes': note_summaries,
                            'total_notes': len(note_summaries),
                            'directory': directory
                        },
                        [
                            f"Process interactively: /notes process-inbox --interactive",
                            f"Review individual note: /notes review-note --file [file_path]"
                        ]
                    )

                # Handle --interactive option: return detailed notes for conversational processing
                if getattr(args, 'interactive', False):
                    # Limit to batch size for interactive processing
                    batch_size = args.batch or 3  # Default to 3 for interactive
                    interactive_notes = notes[:batch_size]

                    note_details = []
                    for i, note in enumerate(interactive_notes):
                        note_details.append({
                            'index': i,
                            'id': str(Path(note.file_path).stem),
                            'file_path': note.file_path,
                            'title': note.frontmatter.get('title', Path(note.file_path).stem),
                            'content_preview': note.content[:500] + ('...' if len(note.content) > 500 else ''),
                            'word_count': note.word_count,
                            'action_items_count': len(note.action_items),
                            'suggested_category': note.suggested_category.value,
                            'confidence': 0.8,  # Mock confidence for now
                            'tags': note.tags,
                            'available_actions': [
                                'categorize',
                                'edit',
                                'skip',
                                'delete'
                            ],
                            'suggested_actions': [
                                f"Move to {note.suggested_category.value}",
                                "Edit content",
                                "Skip for now"
                            ]
                        })

                    return self.format_success_result(
                        'process-inbox',
                        f"Ready to review {len(note_details)} notes interactively",
                        {
                            'mode': 'interactive',
                            'notes': note_details,
                            'remaining': len(notes) - len(interactive_notes),
                            'instructions': "Review each note and choose an action"
                        },
                        [
                            f"Categorize note: /notes review-note --file [file_path] --category [category]",
                            f"Skip to next batch: /notes process-inbox --interactive --batch {batch_size}",
                            f"Edit specific note: code [file_path]"
                        ]
                    )

                # Calculate statistics
                total_words = sum(note.word_count for note in notes)
                total_actions = sum(len(note.action_items) for note in notes)
                completed_actions = sum(
                    sum(1 for item in note.action_items if item.completed)
                    for note in notes
                )

                # Category suggestions if auto-suggest enabled
                suggestions_data = {}
                if args.auto_suggest:
                    suggestions_data = {}
                    for note in notes:
                        if note.suggested_category != ParaCategory.INBOX:
                            suggestions_data[note.file_path] = note.suggested_category.value

                # Limit batch processing if specified
                processed_count = len(notes)
                if args.batch and args.batch < len(notes):
                    notes = notes[:args.batch]
                    processed_count = args.batch

                total_notes = len(notes)
            else:
                # Fallback to subprocess
                cmd = ['./para-processor.py', 'batch', directory, '--summary']
                if args.pattern:
                    cmd.extend(['--pattern', args.pattern])

                result = subprocess.run(cmd, capture_output=True, text=True)

                if result.returncode != 0:
                    return self.format_error_result(
                        'process-inbox',
                        f"Failed to process notes: {result.stderr.strip()}",
                        result.stderr.strip()
                    )

                # Parse subprocess output to extract metrics
                output = result.stdout.strip()

                # Default values
                processed_count = 0
                total_notes = 0
                total_words = 0
                total_actions = 0
                completed_actions = 0
                suggestions_data = {}

                # Parse the output
                for line in output.split('\n'):
                    if 'Processed' in line and 'notes' in line:
                        # Extract number from "📊 Processed 7 notes"
                        parts = line.split()
                        for part in parts:
                            if part.isdigit():
                                processed_count = int(part)
                                total_notes = processed_count
                                break
                    elif 'Total words:' in line:
                        # Extract from "📝 Total words: 817"
                        parts = line.split(':')
                        if len(parts) > 1:
                            try:
                                total_words = int(parts[1].strip())
                            except ValueError:
                                pass
                    elif 'Action items:' in line:
                        # Extract from "✅ Action items: 0/50 completed"
                        parts = line.split(':')
                        if len(parts) > 1:
                            action_part = parts[1].strip()
                            if '/' in action_part:
                                try:
                                    completed_str, total_str = action_part.split('/')
                                    completed_actions = int(completed_str.strip())
                                    total_actions = int(total_str.split()[0])  # Remove 'completed' word
                                except ValueError:
                                    pass

                # Apply batch limit if specified
                if args.batch and args.batch < processed_count:
                    processed_count = args.batch

                if processed_count == 0:
                    return self.format_success_result(
                        'process-inbox',
                        f"No notes found in {directory}",
                        {'notes_processed': 0},
                        [f"Add notes to {directory} directory", "Check file pattern"]
                    )

            return self.format_success_result(
                'process-inbox',
                f"Processed {processed_count} notes from {directory}",
                {
                    'notes_processed': processed_count,
                    'total_notes': total_notes,
                    'total_words': total_words,
                    'action_items': {
                        'total': total_actions,
                        'completed': completed_actions,
                        'pending': total_actions - completed_actions
                    },
                    'suggestions': suggestions_data if args.auto_suggest else {}
                },
                [
                    f"Review suggestions with: /notes review --directory {directory}",
                    f"Find action items with: /notes follow-up --directory {directory}"
                ]
            )

        except Exception as e:
            return self.format_error_result(
                'process-inbox',
                f"Failed to process inbox: {str(e)}",
                str(e),
                ["Check directory permissions", "Verify note file format"]
            )

    def cmd_review_note(self, args) -> CommandResult:
        """Review and process individual notes"""
        try:
            if not args.file:
                return self.format_error_result(
                    'review-note',
                    "No file specified for review",
                    suggestions=["Use --file parameter to specify note to review"]
                )

            file_path = Path(args.file)
            if not file_path.exists():
                return self.format_error_result(
                    'review-note',
                    f"File '{args.file}' does not exist",
                    suggestions=["Check file path", "Use /notes find to locate notes"]
                )

            if not subprocess_mode and self.processor:
                # Parse the note
                note = self.processor.parse_note(str(file_path), validate=False)

                # Handle different actions
                if args.category:
                    # Move note to specified category
                    success = self._move_note_to_category(note, args.category)
                    if success:
                        return self.format_success_result(
                            'review-note',
                            f"Moved '{file_path.name}' to {args.category}",
                            {
                                'action': 'categorize',
                                'file_path': str(file_path),
                                'category': args.category,
                                'original_category': 'inbox'
                            },
                            [
                                f"View moved note: code {self._get_category_path(args.category)}/{file_path.name}",
                                f"Undo move: /notes review-note --file {args.file} --undo-move"
                            ]
                        )
                    else:
                        return self.format_error_result(
                            'review-note',
                            f"Failed to move note to {args.category}",
                            suggestions=["Check category name", "Verify write permissions"]
                        )

                elif getattr(args, 'undo_move', False):
                    # Undo previous move operation
                    return self.format_success_result(
                        'review-note',
                        f"Undo operation not yet implemented",
                        {'action': 'undo', 'status': 'pending'},
                        ["Undo operations coming in future version"]
                    )

                else:
                    # Default: analyze and provide review options
                    review_data = {
                        'file_path': str(file_path),
                        'title': note.frontmatter.get('title', file_path.stem),
                        'content_preview': note.content[:500] + ('...' if len(note.content) > 500 else ''),
                        'full_content': note.content if args.full_content else None,
                        'word_count': note.word_count,
                        'action_items': [
                            {
                                'text': item.text,
                                'completed': item.completed,
                                'assignee': item.assignee,
                                'due_date': item.due_date
                            }
                            for item in note.action_items
                        ],
                        'suggested_category': note.suggested_category.value,
                        'current_category': 'inbox',
                        'confidence': 0.8,  # Mock confidence
                        'tags': note.tags,
                        'available_actions': [
                            'categorize',
                            'edit',
                            'delete',
                            'skip'
                        ],
                        'category_options': [
                            'projects',
                            'areas',
                            'resources',
                            'archive'
                        ]
                    }

                    return self.format_success_result(
                        'review-note',
                        f"Review options for '{file_path.name}'",
                        review_data,
                        [
                            f"Categorize: /notes review-note --file {args.file} --category {note.suggested_category.value}",
                            f"Edit: code {args.file}",
                            f"Skip: /notes process-inbox --interactive"
                        ]
                    )
            else:
                # Fallback for subprocess mode
                return self.format_error_result(
                    'review-note',
                    "Review note functionality requires native mode",
                    suggestions=["Install required dependencies for native mode"]
                )

        except Exception as e:
            return self.format_error_result(
                'review-note',
                f"Review failed: {str(e)}",
                str(e),
                ["Check file permissions", "Verify file format"]
            )

    def _move_note_to_category(self, note, category: str) -> bool:
        """Move a note to the specified PARA category"""
        try:
            source_path = Path(note.file_path)

            # Create category directory if it doesn't exist
            category_dir = Path(self._get_category_path(category))
            category_dir.mkdir(parents=True, exist_ok=True)

            # Move the file
            destination_path = category_dir / source_path.name
            source_path.rename(destination_path)

            return True
        except Exception as e:
            return False

    def _get_category_path(self, category: str) -> str:
        """Get the directory path for a PARA category"""
        category_paths = {
            'projects': '1-projects',
            'areas': '2-areas',
            'resources': '3-resources',
            'archive': '4-archive'
        }
        return category_paths.get(category, category)

    def cmd_research(self, args) -> CommandResult:
        """Enhanced research and analysis with web search and cross-referencing"""
        try:
            if not args.file:
                return self.format_error_result(
                    'research',
                    "No file specified for research",
                    suggestions=["Use --file parameter to specify note to analyze"]
                )

            if not subprocess_mode and self.processor:
                # Single file analysis
                note = self.processor.parse_note(args.file, validate=not args.graceful)

                # Extract research-relevant information
                research_data = {
                    'file_path': note.file_path,
                    'word_count': note.word_count,
                    'read_time': note.estimated_read_time,
                    'category': note.suggested_category.value,
                    'tags': note.tags,
                    'key_dates': note.dates,
                    'action_items': len(note.action_items),
                    'attendees': note.attendees
                }

                # Determine research query
                research_query = args.query
                if not research_query:
                    # Auto-detect from file title, tags, or content
                    if 'title' in note.frontmatter:
                        research_query = note.frontmatter['title']
                    elif note.tags:
                        research_query = ' '.join(note.tags[:3])  # Use first 3 tags
                    else:
                        # Extract first meaningful sentence/phrase from content
                        lines = note.content.split('\n')
                        for line in lines:
                            line = line.strip()
                            if line and not line.startswith('#') and len(line) > 10:
                                research_query = line[:100]  # First 100 chars
                                break

                # Topic expansion if requested
                expanded_topics = []
                if args.expand_topics:
                    expanded_topics = self._find_related_topics(note)

                # Web search enhancement if requested
                web_research = {}
                if args.web_search and research_query:
                    web_research = self._perform_web_research(research_query)

                # Cross-reference with existing notes if requested
                related_notes = []
                if args.cross_reference:
                    related_notes = self._find_related_notes(note, args.limit)

                # Build comprehensive response
                response_data = {
                    'analysis': research_data,
                    'research_query': research_query,
                    'expanded_topics': expanded_topics,
                    'web_research': web_research,
                    'related_notes': related_notes,
                    'sources': self._collect_sources(web_research, related_notes)
                }

                suggestions = [
                    f"Open file: code {args.file}"
                ]

                if related_notes:
                    suggestions.append(f"Open related note: code {related_notes[0]['path']}")

                if web_research:
                    suggestions.append("Enhance note with research: /notes enhance --file " + args.file + " --web-search")

                if not args.cross_reference:
                    suggestions.append("Find connections: /notes connect --file " + args.file)

                return self.format_success_result(
                    'research',
                    f"Researched note: {Path(args.file).name}" + (f" on topic '{research_query}'" if research_query else ""),
                    response_data,
                    suggestions
                )

            else:
                # Fallback for subprocess mode
                return self.format_error_result(
                    'research',
                    "Enhanced research functionality requires native mode",
                    suggestions=["Install required dependencies for native mode", "Use basic file analysis with para-processor.py"]
                )

        except Exception as e:
            return self.format_error_result(
                'research',
                f"Research failed: {str(e)}",
                str(e),
                ["Check file path exists", "Use --graceful for malformed notes"]
            )

    def cmd_enhance(self, args) -> CommandResult:
        """Enhance notes with additional context while preserving original content"""
        try:
            if not Path(args.file).exists():
                return self.format_error_result(
                    'enhance',
                    f"File '{args.file}' does not exist",
                    suggestions=["Check file path", "Use /notes find to locate notes"]
                )

            # Parse the original note
            note = self.processor.parse_note(args.file, validate=False)

            # Determine enhancement topic
            enhancement_topic = args.topic
            if not enhancement_topic:
                # Auto-detect from note content like in research
                if 'title' in note.frontmatter:
                    enhancement_topic = note.frontmatter['title']
                elif note.tags:
                    enhancement_topic = ' '.join(note.tags[:2])
                else:
                    # Extract from first meaningful line
                    lines = note.content.split('\n')
                    for line in lines:
                        line = line.strip()
                        if line and not line.startswith('#') and len(line) > 10:
                            enhancement_topic = line[:50]  # First 50 chars
                            break

            # Collect enhancement data
            enhancement_data = {
                'original_file': args.file,
                'enhancement_topic': enhancement_topic,
                'original_content_preserved': True,
                'enhancements_added': []
            }

            # Web search enhancement
            if args.web_search and enhancement_topic:
                web_enhancement = self._perform_web_research(enhancement_topic)
                enhancement_data['enhancements_added'].append({
                    'type': 'web_search',
                    'topic': enhancement_topic,
                    'data': web_enhancement
                })

            # Cross-reference enhancement
            if args.cross_reference:
                related_notes = self._find_related_notes(note, 5)
                enhancement_data['enhancements_added'].append({
                    'type': 'cross_reference',
                    'related_notes_count': len(related_notes),
                    'data': related_notes
                })

            # Create enhancement content structure
            enhancement_content = self._create_enhanced_content(
                note,
                enhancement_data['enhancements_added'],
                preserve_original=args.preserve_original
            )

            # Write enhanced content
            output_file = args.output or args.file
            if args.preserve_original:
                # Create backup if overwriting original
                if output_file == args.file:
                    backup_path = f"{args.file}.backup-{datetime.datetime.now().strftime('%Y%m%d-%H%M%S')}"
                    Path(args.file).rename(backup_path)
                    enhancement_data['backup_created'] = backup_path

            # Write the enhanced content
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(enhancement_content)

            enhancement_data['output_file'] = output_file
            enhancement_data['enhancement_sections'] = len(enhancement_data['enhancements_added'])

            return self.format_success_result(
                'enhance',
                f"Enhanced note: {Path(args.file).name}" + (f" with {len(enhancement_data['enhancements_added'])} enhancements" if enhancement_data['enhancements_added'] else ""),
                enhancement_data,
                [
                    f"View enhanced note: code {output_file}",
                    f"Compare with original: code {enhancement_data.get('backup_created', args.file)} {output_file}" if enhancement_data.get('backup_created') else None,
                    "Research more topics: /notes research --file " + output_file + " --web-search --cross-reference"
                ]
            )

        except Exception as e:
            return self.format_error_result(
                'enhance',
                f"Enhancement failed: {str(e)}",
                str(e),
                ["Check file permissions", "Verify file format", "Try with --preserve-original"]
            )

    def cmd_connect(self, args) -> CommandResult:
        """Find connections between notes based on content and themes"""
        try:
            connections = []
            connection_query = args.query

            if args.file:
                # Find connections for a specific file
                if not Path(args.file).exists():
                    return self.format_error_result(
                        'connect',
                        f"File '{args.file}' does not exist",
                        suggestions=["Check file path", "Use /notes find to locate notes"]
                    )

                note = self.processor.parse_note(args.file, validate=False)
                related_notes = self._find_related_notes(note, args.limit)

                # Convert to connection format
                for related in related_notes:
                    connections.append({
                        'source_file': Path(args.file).name,
                        'target_file': related['file'],
                        'connection_strength': related['similarity_score'],
                        'connection_type': 'content_similarity',
                        'shared_elements': {
                            'tag_overlap': related['tag_overlap'],
                            'word_overlap': related['word_overlap']
                        },
                        'target_path': related['path'],
                        'target_category': related['category']
                    })

                connection_summary = f"Found {len(connections)} connections for {Path(args.file).name}"

            elif connection_query:
                # Find connections around a theme/topic
                all_notes = self.processor.batch_process_notes(args.directory, '*.md')
                query_lower = connection_query.lower()
                relevant_notes = []

                # Find notes related to the query
                for note in all_notes:
                    relevance_score = 0

                    # Check tags
                    if any(query_lower in tag.lower() for tag in note.tags):
                        relevance_score += 3.0

                    # Check content
                    if query_lower in note.content.lower():
                        relevance_score += note.content.lower().count(query_lower) * 0.5

                    if relevance_score >= args.similarity_threshold:
                        relevant_notes.append({
                            'note': note,
                            'relevance': relevance_score
                        })

                # Create connections between relevant notes
                for i, note_a in enumerate(relevant_notes):
                    for note_b in relevant_notes[i+1:]:
                        # Calculate connection strength between these two notes
                        shared_tags = set(note_a['note'].tags) & set(note_b['note'].tags)
                        connection_strength = len(shared_tags) * 2.0 + min(note_a['relevance'], note_b['relevance']) * 0.3

                        if connection_strength >= args.similarity_threshold:
                            connections.append({
                                'source_file': Path(note_a['note'].file_path).name,
                                'target_file': Path(note_b['note'].file_path).name,
                                'connection_strength': round(connection_strength, 2),
                                'connection_type': 'thematic_similarity',
                                'shared_elements': {
                                    'shared_tags': list(shared_tags),
                                    'query_relevance': [note_a['relevance'], note_b['relevance']]
                                },
                                'source_path': note_a['note'].file_path,
                                'target_path': note_b['note'].file_path
                            })

                # Sort by connection strength
                connections.sort(key=lambda x: x['connection_strength'], reverse=True)
                connections = connections[:args.limit]

                connection_summary = f"Found {len(connections)} thematic connections for '{connection_query}'"

            else:
                return self.format_error_result(
                    'connect',
                    "Must specify either --file or --query parameter",
                    suggestions=["Use --file to find connections for a specific note", "Use --query to find thematic connections"]
                )

            # Build response
            response_data = {
                'connection_query': connection_query,
                'source_file': args.file,
                'total_connections': len(connections),
                'connections': connections,
                'analysis': {
                    'strongest_connection': max(connections, key=lambda x: x['connection_strength'])['connection_strength'] if connections else 0,
                    'connection_types': list(set(c['connection_type'] for c in connections)),
                    'unique_files': len(set([c['source_file'] for c in connections] + [c['target_file'] for c in connections]))
                }
            }

            suggestions = []
            if connections:
                strongest = max(connections, key=lambda x: x['connection_strength'])
                suggestions.extend([
                    f"Explore connection: code {strongest.get('source_path', strongest['source_file'])}",
                    f"View related note: code {strongest.get('target_path', strongest['target_file'])}"
                ])
                if args.file:
                    suggestions.append(f"Research connections: /notes research --file {args.file} --cross-reference")
            else:
                suggestions.extend([
                    "Try lowering --similarity-threshold",
                    "Expand search with different query terms"
                ])

            return self.format_success_result(
                'connect',
                connection_summary,
                response_data,
                suggestions
            )

        except Exception as e:
            return self.format_error_result(
                'connect',
                f"Connection analysis failed: {str(e)}",
                str(e),
                ["Check directory exists", "Verify file permissions", "Try with different parameters"]
            )

    def cmd_find(self, args) -> CommandResult:
        """Enhanced find with advanced search capabilities"""
        try:
            directory = args.directory or '.'

            # Get all notes in directory
            notes = self.processor.batch_process_notes(directory, '*.md')

            # Track applied filters for user feedback
            filters_applied = []

            # 1. Similarity search (if specified, this becomes the primary filter)
            if args.similar:
                notes, similarity_info = self._apply_similarity_filter(notes, args.similar)
                filters_applied.append(f"similar to '{Path(args.similar).name}'")

            # 2. Text query filter (enhanced scoring)
            if args.query:
                notes = self._apply_query_filter(notes, args.query)
                filters_applied.append(f"query: '{args.query}'")

            # 3. Tag-based filtering
            if args.tags:
                notes = self._apply_tag_filter(notes, args.tags)
                filters_applied.append(f"tags: {args.tags}")

            # 4. Attendee-based filtering
            if args.attendees:
                notes = self._apply_attendee_filter(notes, args.attendees)
                filters_applied.append(f"attendees: {args.attendees}")

            # 5. Category filtering
            if args.category:
                notes = self._apply_category_filter(notes, args.category)
                filters_applied.append(f"category: {args.category}")

            # 6. Date range filtering (preset)
            if args.date_range:
                notes = self._filter_by_date_range(notes, args.date_range)
                filters_applied.append(f"date range: {args.date_range}")

            # 7. Custom date range filtering
            if args.date_from or args.date_to:
                notes = self._apply_custom_date_filter(notes, args.date_from, args.date_to)
                date_filter_desc = f"from {args.date_from or 'beginning'} to {args.date_to or 'now'}"
                filters_applied.append(f"custom dates: {date_filter_desc}")

            # Sort by relevance/recency (enhanced algorithm)
            notes = self._sort_search_results(notes, args.query, args.similar)

            # Limit results
            limit = args.limit or 10
            total_matches = len(notes)
            results = notes[:limit]

            # Format results with enhanced information
            result_data = []
            for note_data in results:
                note = note_data['note'] if isinstance(note_data, dict) else note_data

                result_entry = {
                    'file': str(Path(note.file_path).name),
                    'path': note.file_path,
                    'words': note.word_count,
                    'tags': note.tags,
                    'category': note.suggested_category.value if hasattr(note.suggested_category, 'value') else str(note.suggested_category),
                    'action_items': len([item for item in note.action_items if not item.completed]),
                    'attendees': note.attendees[:3] if note.attendees else []  # Show first 3 attendees
                }

                # Add relevance score if available
                if isinstance(note_data, dict) and 'score' in note_data:
                    result_entry['relevance_score'] = round(note_data['score'], 2)

                # Add content preview if requested
                if args.preview:
                    preview_text = self._extract_content_preview(note, args.query)
                    result_entry['preview'] = preview_text

                # Add similarity info if similarity search was used
                if args.similar and isinstance(note_data, dict) and 'similarity' in note_data:
                    result_entry['similarity'] = round(note_data['similarity'], 2)

                result_data.append(result_entry)

            # Generate search summary
            search_summary = f"Found {total_matches} matching notes"
            if filters_applied:
                search_summary += f" (filters: {', '.join(filters_applied)})"

            # Generate helpful suggestions
            suggestions = []
            if result_data:
                first_result = result_data[0]
                suggestions.append(f"Open result: code {first_result['path']}")
            if total_matches > limit:
                suggestions.append(f"See more: add --limit {min(total_matches, 50)} to see more results")
            if args.query and not args.preview:
                suggestions.append("Add --preview to see content snippets")
            if not args.similar and result_data:
                first_result = result_data[0]
                suggestions.append(f"Find similar: --similar {first_result['path']}")

            # Build response data
            response_data = {
                'search_terms': {
                    'query': args.query,
                    'tags': args.tags,
                    'attendees': args.attendees,
                    'category': args.category,
                    'similar_to': args.similar
                },
                'filters_applied': filters_applied,
                'total_matches': total_matches,
                'results_shown': len(results),
                'results': result_data
            }

            # Add similarity search info if used
            if args.similar:
                response_data['similarity_search'] = similarity_info if 'similarity_info' in locals() else {
                    'reference_file': args.similar,
                    'method': 'content_similarity'
                }

            return self.format_success_result(
                'find',
                search_summary,
                response_data,
                suggestions
            )

        except Exception as e:
            return self.format_error_result(
                'find',
                f"Search failed: {str(e)}",
                str(e),
                ["Check directory exists", "Verify search parameters", "Check file paths"]
            )

    def cmd_follow_up(self, args) -> CommandResult:
        """Manage action items and follow-ups"""
        try:
            directory = args.directory or '.'

            if args.status == 'overdue':
                # Find orphaned/overdue action items
                orphaned_items = self.processor.find_orphaned_action_items(directory)

                action_data = []
                for file_path, action_item in orphaned_items:
                    action_data.append({
                        'file': str(Path(file_path).name),
                        'path': file_path,
                        'text': action_item.text,
                        'line': action_item.line_number,
                        'assignee': action_item.assignee,
                        'due_date': action_item.due_date,
                        'priority': action_item.priority
                    })

                return self.format_success_result(
                    'follow-up',
                    f"Found {len(action_data)} overdue/orphaned action items",
                    {
                        'status': 'overdue',
                        'total_items': len(action_data),
                        'items': action_data[:10]  # Limit display
                    },
                    [
                        f"Review item: code {action_data[0]['path']}:{action_data[0]['line']}" if action_data else None,
                        "Update due dates and assignees"
                    ]
                )

            else:
                # General action item summary
                notes = self.processor.batch_process_notes(directory, '*.md')
                all_actions = []

                for note in notes:
                    for action in note.action_items:
                        if args.assignee and args.assignee.lower() not in (action.assignee or '').lower():
                            continue

                        all_actions.append({
                            'file': str(Path(note.file_path).name),
                            'path': note.file_path,
                            'text': action.text,
                            'completed': action.completed,
                            'assignee': action.assignee,
                            'due_date': action.due_date,
                            'priority': action.priority
                        })

                incomplete_count = len([a for a in all_actions if not a['completed']])

                return self.format_success_result(
                    'follow-up',
                    f"Found {len(all_actions)} action items ({incomplete_count} incomplete)",
                    {
                        'total_items': len(all_actions),
                        'incomplete': incomplete_count,
                        'completed': len(all_actions) - incomplete_count,
                        'items': all_actions[:10]
                    },
                    [
                        "Focus on incomplete items",
                        "Set due dates and assignees for better tracking"
                    ]
                )

        except Exception as e:
            return self.format_error_result(
                'follow-up',
                f"Follow-up failed: {str(e)}",
                str(e),
                ["Check directory permissions", "Verify action item format"]
            )

    def cmd_prep(self, args) -> CommandResult:
        """Prepare comprehensive meeting briefs using attendee and topic-based analysis"""
        try:
            topic = args.topic or 'Meeting Preparation'
            attendees = args.attendees or ''

            # Create comprehensive meeting brief
            brief_data = {
                'meeting_info': {
                    'topic': topic,
                    'attendees': attendees.split(',') if attendees else [],
                    'date': datetime.date.today().strftime('%Y-%m-%d'),
                    'prep_time': datetime.datetime.now().strftime('%H:%M')
                },
                'context': {},
                'actions': {},
                'agenda': {},
                'confidence_scores': {}
            }

            # Gather historical context
            try:
                context_args = argparse.Namespace(
                    topic=topic,
                    attendees=attendees,
                    days_back=90,
                    max_results=10
                )
                context_result = self.cmd_gather_context(context_args)
                if context_result.success:
                    brief_data['context'] = context_result.data
                    brief_data['confidence_scores']['context'] = 0.9
            except Exception as e:
                brief_data['context'] = {'error': f'Context gathering failed: {str(e)}'}
                brief_data['confidence_scores']['context'] = 0.3

            # Check outstanding actions
            try:
                actions_args = argparse.Namespace(
                    attendees=attendees,
                    topic=topic,
                    status='pending'
                )
                actions_result = self.cmd_check_actions(actions_args)
                if actions_result.success:
                    brief_data['actions'] = actions_result.data
                    brief_data['confidence_scores']['actions'] = 0.95
            except Exception as e:
                brief_data['actions'] = {'error': f'Action check failed: {str(e)}'}
                brief_data['confidence_scores']['actions'] = 0.3

            # Generate agenda suggestions
            try:
                agenda_args = argparse.Namespace(
                    attendees=attendees,
                    topic=topic,
                    meeting_type='general'
                )
                agenda_result = self.cmd_suggest_agenda(agenda_args)
                if agenda_result.success:
                    brief_data['agenda'] = agenda_result.data
                    brief_data['confidence_scores']['agenda'] = 0.85
            except Exception as e:
                brief_data['agenda'] = {'error': f'Agenda generation failed: {str(e)}'}
                brief_data['confidence_scores']['agenda'] = 0.3

            # Create meeting prep note with comprehensive data
            prep_content = self._format_meeting_brief(brief_data)

            # Create output file directly with comprehensive content
            if args.output:
                output_path = args.output
            else:
                output_path = f"meeting-brief-{datetime.date.today().strftime('%Y-%m-%d')}-{topic.lower().replace(' ', '-')}.md"

            with open(output_path, 'w') as f:
                f.write(prep_content)
            brief_data['prep_file'] = output_path

            # Calculate overall confidence and provide summary
            overall_confidence = sum(brief_data['confidence_scores'].values()) / len(brief_data['confidence_scores'])

            # Count actionable items found
            total_context = len(brief_data.get('context', {}).get('topic_matches', [])) + len(brief_data.get('context', {}).get('attendee_matches', []))
            total_actions = len(brief_data.get('actions', {}).get('pending_actions', [])) + len(brief_data.get('actions', {}).get('attendee_related', []))
            agenda_items = len(brief_data.get('agenda', {}).get('suggested_agenda', []))

            summary_message = f"Generated comprehensive meeting brief: {total_context} context items, {total_actions} action items, {agenda_items} agenda suggestions (confidence: {overall_confidence:.1%})"

            return self.format_success_result(
                'prep',
                summary_message,
                brief_data,
                [
                    f"Review meeting brief: code {brief_data.get('prep_file', 'meeting-brief.md')}",
                    "Check outstanding action items for follow-up",
                    "Customize agenda based on meeting objectives",
                    "Share relevant context with attendees if needed"
                ]
            )

        except Exception as e:
            return self.format_error_result(
                'prep',
                f"Comprehensive meeting prep failed: {str(e)}",
                str(e),
                ["Check topic and attendees format", "Verify system access to notes", "Try basic prep mode"]
            )

    def _format_meeting_brief(self, brief_data):
        """Format comprehensive meeting brief content"""
        content = f"""# Meeting Brief: {brief_data['meeting_info']['topic']}

**Date:** {brief_data['meeting_info']['date']}
**Attendees:** {', '.join(brief_data['meeting_info']['attendees'])}
**Prepared:** {brief_data['meeting_info']['prep_time']}

## Context & Background

"""
        # Add context information
        if 'context' in brief_data and 'topic_matches' in brief_data['context']:
            content += "### Topic-Related Notes\n"
            for match in brief_data['context']['topic_matches'][:3]:
                content += f"- **{match['file']}**: {match['summary']}\n"
            content += "\n"

        if 'context' in brief_data and 'attendee_matches' in brief_data['context']:
            content += "### Attendee History\n"
            for match in brief_data['context']['attendee_matches'][:3]:
                content += f"- **{match['attendee']}**: {match['summary']}\n"
            content += "\n"

        # Add action items
        content += "## Outstanding Actions\n\n"
        if 'actions' in brief_data:
            if brief_data['actions'].get('overdue_actions'):
                content += "### ⚠️ Overdue Items\n"
                for action in brief_data['actions']['overdue_actions'][:3]:
                    content += f"- **{action['assignee']}**: {action['task']}\n"
                content += "\n"

            if brief_data['actions'].get('attendee_related'):
                content += "### Attendee-Specific Actions\n"
                for action in brief_data['actions']['attendee_related'][:5]:
                    content += f"- **{action['assignee']}**: {action['task']} ({action['status']})\n"
                content += "\n"

        # Add suggested agenda
        content += "## Suggested Agenda\n\n"
        if 'agenda' in brief_data and 'suggested_agenda' in brief_data['agenda']:
            for i, item in enumerate(brief_data['agenda']['suggested_agenda'], 1):
                content += f"{i}. {item}\n"

        content += """

## Meeting Notes

[Add your meeting notes here]

## Action Items

- [ ]
- [ ]
- [ ]

## Next Steps

[Define next steps and follow-up actions]

---
*Generated by Claude Code Meeting Preparation System*
"""
        return content

    def cmd_gather_context(self, args) -> CommandResult:
        """Retrieve and synthesize relevant historical information"""
        try:
            topic = args.topic or ''
            attendees = args.attendees or ''
            attendee_list = [a.strip() for a in attendees.split(',') if a.strip()] if attendees else []

            # Search for relevant notes
            context_data = {
                'topic_matches': [],
                'attendee_matches': [],
                'recent_notes': [],
                'summary': ''
            }

            if self.processor:
                notes = self.processor.batch_process_notes('.', '*.md')
                cutoff_date = datetime.datetime.now() - datetime.timedelta(days=args.days_back)

                topic_matches = []
                attendee_matches = []
                recent_notes = []

                for note in notes:
                    # Check modification date
                    try:
                        note_date = datetime.datetime.fromtimestamp(os.path.getmtime(note.file_path))
                        if note_date < cutoff_date:
                            continue
                    except:
                        continue

                    # Topic matching
                    if topic and topic.lower() in note.content.lower():
                        topic_matches.append({
                            'file': str(Path(note.file_path).name),
                            'path': note.file_path,
                            'relevance_score': note.content.lower().count(topic.lower()),
                            'summary': note.content[:200] + '...' if len(note.content) > 200 else note.content
                        })

                    # Attendee matching
                    for attendee in attendee_list:
                        if attendee.lower() in note.content.lower():
                            attendee_matches.append({
                                'file': str(Path(note.file_path).name),
                                'path': note.file_path,
                                'attendee': attendee,
                                'summary': note.content[:200] + '...' if len(note.content) > 200 else note.content
                            })
                            break

                    # Recent notes
                    recent_notes.append({
                        'file': str(Path(note.file_path).name),
                        'path': note.file_path,
                        'modified': note_date.strftime('%Y-%m-%d'),
                        'summary': note.content[:150] + '...' if len(note.content) > 150 else note.content
                    })

                # Sort and limit results
                topic_matches.sort(key=lambda x: x['relevance_score'], reverse=True)
                context_data['topic_matches'] = topic_matches[:args.max_results//2]
                context_data['attendee_matches'] = attendee_matches[:args.max_results//2]
                context_data['recent_notes'] = recent_notes[:5]

                # Generate summary
                total_matches = len(topic_matches) + len(attendee_matches)
                context_data['summary'] = f"Found {total_matches} relevant notes from the last {args.days_back} days"

            return self.format_success_result(
                'gather-context',
                f"Gathered context for {topic or 'meeting'}" + (f" with {len(attendee_list)} attendees" if attendee_list else ""),
                context_data,
                ["Review topic matches for relevant background", "Check attendee-specific notes for context"]
            )

        except Exception as e:
            return self.format_error_result(
                'gather-context',
                f"Context gathering failed: {str(e)}",
                str(e),
                ["Check topic and attendee parameters", "Verify access to note files"]
            )

    def cmd_check_actions(self, args) -> CommandResult:
        """Identify outstanding action items related to meeting participants/topics"""
        try:
            attendees = args.attendees or ''
            topic = args.topic or ''
            attendee_list = [a.strip() for a in attendees.split(',') if a.strip()] if attendees else []

            # Use existing follow-up functionality
            action_items = {
                'pending_actions': [],
                'overdue_actions': [],
                'topic_related': [],
                'attendee_related': []
            }

            if self.processor:
                notes = self.processor.batch_process_notes('.', '*.md')

                for note in notes:
                    # Extract action items from each note
                    for action in note.action_items:
                        # Determine status from completed and due_date
                        if action.completed:
                            status = 'completed'
                        elif action.due_date:
                            try:
                                due_date = datetime.datetime.strptime(action.due_date, '%Y-%m-%d')
                                if due_date < datetime.datetime.now():
                                    status = 'overdue'
                                else:
                                    status = 'pending'
                            except:
                                status = 'pending'
                        else:
                            status = 'pending'

                        action_dict = {
                            'task': action.text,
                            'assignee': action.assignee or 'unassigned',
                            'due_date': action.due_date,
                            'status': status,
                            'completed': action.completed,
                            'file': str(Path(note.file_path).name),
                            'path': note.file_path
                        }

                        # Filter by status
                        if args.status == 'all' or status == args.status:
                            # Check if action is related to attendees
                            if attendee_list and action.assignee and any(attendee.lower() in action.assignee.lower() for attendee in attendee_list):
                                action_items['attendee_related'].append(action_dict)

                            # Check if action is related to topic
                            if topic and topic.lower() in action.text.lower():
                                action_items['topic_related'].append(action_dict)

                            # Categorize by status
                            if status == 'pending':
                                action_items['pending_actions'].append(action_dict)
                            elif status == 'overdue':
                                action_items['overdue_actions'].append(action_dict)

            total_actions = len(action_items['pending_actions']) + len(action_items['overdue_actions'])
            related_actions = len(action_items['topic_related']) + len(action_items['attendee_related'])

            return self.format_success_result(
                'check-actions',
                f"Found {total_actions} total actions, {related_actions} related to meeting context",
                action_items,
                [
                    "Review overdue actions that need immediate attention",
                    "Address pending actions related to meeting attendees",
                    "Include relevant action items in meeting agenda"
                ]
            )

        except Exception as e:
            return self.format_error_result(
                'check-actions',
                f"Action check failed: {str(e)}",
                str(e),
                ["Verify attendee and topic parameters", "Check action item parsing"]
            )

    def cmd_suggest_agenda(self, args) -> CommandResult:
        """Propose agenda items based on historical meeting patterns and outstanding items"""
        try:
            attendees = args.attendees or ''
            topic = args.topic or ''
            meeting_type = args.meeting_type
            attendee_list = [a.strip() for a in attendees.split(',') if a.strip()] if attendees else []

            agenda_suggestions = {
                'standard_items': [],
                'topic_specific': [],
                'action_follow_ups': [],
                'recurring_themes': [],
                'suggested_agenda': []
            }

            # Standard agenda items based on meeting type
            if meeting_type == '1-on-1':
                agenda_suggestions['standard_items'] = [
                    "Personal check-in and well-being",
                    "Current project status and challenges",
                    "Goals and priorities discussion",
                    "Feedback and development topics",
                    "Action items and next steps"
                ]
            elif meeting_type == 'team-meeting':
                agenda_suggestions['standard_items'] = [
                    "Team updates and announcements",
                    "Project status reviews",
                    "Blockers and challenges",
                    "Upcoming deadlines and priorities",
                    "Team collaboration topics"
                ]
            elif meeting_type == 'project-review':
                agenda_suggestions['standard_items'] = [
                    "Project milestone review",
                    "Current status and metrics",
                    "Risks and mitigation strategies",
                    "Resource needs and constraints",
                    "Next phase planning"
                ]
            else:  # general
                agenda_suggestions['standard_items'] = [
                    "Meeting objectives review",
                    "Key discussion topics",
                    "Decision items",
                    "Action planning"
                ]

            if self.processor:
                notes = self.processor.batch_process_notes('.', '*.md')

                # Analyze historical patterns
                topic_themes = {}
                recent_actions = []

                for note in notes:
                    # Look for patterns in attendee-related meetings
                    if attendee_list:
                        note_content_lower = note.content.lower()
                        if any(attendee.lower() in note_content_lower for attendee in attendee_list):
                            # Extract common themes from note content
                            words = re.findall(r'\b\w+\b', note_content_lower)
                            for word in words:
                                if len(word) > 4 and word not in ['meeting', 'discussion', 'action', 'item']:
                                    topic_themes[word] = topic_themes.get(word, 0) + 1

                    # Collect recent action items for follow-up
                    for action in note.action_items:
                        # Determine status from completed and due_date
                        if action.completed:
                            status = 'completed'
                        elif action.due_date:
                            try:
                                due_date = datetime.datetime.strptime(action.due_date, '%Y-%m-%d')
                                if due_date < datetime.datetime.now():
                                    status = 'overdue'
                                else:
                                    status = 'pending'
                            except:
                                status = 'pending'
                        else:
                            status = 'pending'

                        if status in ['pending', 'overdue']:
                            if not attendee_list or (action.assignee and any(attendee.lower() in action.assignee.lower() for attendee in attendee_list)):
                                recent_actions.append({
                                    'task': action.text,
                                    'assignee': action.assignee or 'unassigned',
                                    'status': status
                                })

                # Generate topic-specific suggestions
                if topic:
                    agenda_suggestions['topic_specific'] = [
                        f"{topic} - current status and progress",
                        f"{topic} - challenges and blockers",
                        f"{topic} - next steps and timeline"
                    ]

                # Add recurring themes
                common_themes = sorted(topic_themes.items(), key=lambda x: x[1], reverse=True)[:3]
                agenda_suggestions['recurring_themes'] = [theme[0].title() for theme in common_themes]

                # Add action follow-ups
                agenda_suggestions['action_follow_ups'] = recent_actions[:5]

            # Build suggested agenda
            suggested_agenda = []
            suggested_agenda.extend(agenda_suggestions['standard_items'][:3])  # Top 3 standard items

            if agenda_suggestions['topic_specific']:
                suggested_agenda.extend(agenda_suggestions['topic_specific'][:2])

            if agenda_suggestions['action_follow_ups']:
                suggested_agenda.append("Action item follow-up")

            if agenda_suggestions['recurring_themes']:
                suggested_agenda.append(f"Discussion: {', '.join(agenda_suggestions['recurring_themes'][:2])}")

            agenda_suggestions['suggested_agenda'] = suggested_agenda

            return self.format_success_result(
                'suggest-agenda',
                f"Generated {len(suggested_agenda)} agenda items for {meeting_type} meeting",
                agenda_suggestions,
                [
                    "Review and customize suggested agenda items",
                    "Add time estimates for each agenda item",
                    "Share agenda with attendees before meeting"
                ]
            )

        except Exception as e:
            return self.format_error_result(
                'suggest-agenda',
                f"Agenda suggestion failed: {str(e)}",
                str(e),
                ["Check meeting parameters", "Verify access to historical notes"]
            )

    def cmd_list_templates(self, args) -> CommandResult:
        """List available note templates"""
        try:
            if not subprocess_mode and self.template_engine:
                # Use native method
                templates = self.template_engine.list_templates()

                template_data = {}
                for category, template_list in templates.items():
                    template_data[category] = []
                    for template in template_list:
                        info = self.template_engine.get_template_info(template)
                        template_data[category].append({
                            'name': template,
                            'description': info.get('description', 'No description') if info else 'No description'
                        })

                total_templates = sum(len(tlist) for tlist in templates.values())
            else:
                # Fallback to subprocess
                result = subprocess.run(['./para-templates.py', 'list'],
                                      capture_output=True, text=True, check=True)
                output = result.stdout.strip()

                # Parse the output to extract template information
                template_data = {'Built-in': [], 'Custom': []}
                current_category = None
                total_templates = 0

                for line in output.split('\n'):
                    line_stripped = line.strip()
                    if line_stripped == 'Built-in:':
                        current_category = 'Built-in'
                    elif line_stripped == 'Custom:':
                        current_category = 'Custom'
                    elif line and current_category and line.startswith('  ') and ' - ' in line:
                        # Parse template line: "  template_name - description"
                        parts = line.strip().split(' - ', 1)
                        if len(parts) == 2:
                            name = parts[0].strip()
                            description = parts[1].strip()
                            template_data[current_category].append({
                                'name': name,
                                'description': description
                            })
                            total_templates += 1

            return self.format_success_result(
                'list-templates',
                f"Found {total_templates} available templates",
                {
                    'templates': template_data,
                    'total': total_templates
                },
                [
                    "Create note: /notes capture --template meeting --topic 'Your Topic'",
                    "View template details: /notes template-info --name meeting"
                ]
            )

        except Exception as e:
            return self.format_error_result(
                'list-templates',
                f"Failed to list templates: {str(e)}",
                str(e)
            )

    def _find_related_topics(self, note: 'ParsedNote') -> List[str]:
        """Find topics related to the current note"""
        topics = []

        # Extract topics from tags
        topics.extend(note.tags)

        # Extract topics from common patterns in content
        topic_patterns = [
            r'(?:topic|subject|about|regarding|concerning):\s*([^\n]+)',
            r'#\s*([A-Za-z][A-Za-z0-9\s-]+)',  # Headings
        ]

        for pattern in topic_patterns:
            matches = re.findall(pattern, note.content, re.IGNORECASE)
            topics.extend([m.strip() for m in matches if len(m.strip()) > 2])

        # Remove duplicates and return unique topics
        return list(set(topics))[:10]  # Limit to 10 topics

    def _apply_similarity_filter(self, notes: List['ParsedNote'], reference_file: str) -> tuple:
        """Find notes similar to the reference file using content similarity"""
        try:
            # Parse the reference file
            reference_note = self.processor.parse_note(reference_file)
            reference_words = set(reference_note.content.lower().split())

            # Remove common words for better similarity matching
            common_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'this', 'that', 'these', 'those'}
            reference_words -= common_words

            similar_notes = []
            for note in notes:
                if note.file_path == reference_file:
                    continue  # Skip the reference file itself

                note_words = set(note.content.lower().split()) - common_words

                # Calculate word overlap similarity (Jaccard index)
                if len(reference_words) > 0 and len(note_words) > 0:
                    intersection = len(reference_words & note_words)
                    union = len(reference_words | note_words)
                    similarity = intersection / union if union > 0 else 0

                    # Also consider tag similarity
                    ref_tags = set(reference_note.tags)
                    note_tags = set(note.tags)
                    if ref_tags and note_tags:
                        tag_similarity = len(ref_tags & note_tags) / len(ref_tags | note_tags)
                        similarity = (similarity * 0.8) + (tag_similarity * 0.2)  # Weight content higher

                    if similarity > 0.05:  # Only include notes with some similarity
                        similar_notes.append({
                            'note': note,
                            'similarity': similarity,
                            'score': similarity * 100  # For sorting compatibility
                        })

            # Sort by similarity
            similar_notes.sort(key=lambda x: x['similarity'], reverse=True)

            similarity_info = {
                'reference_file': reference_file,
                'method': 'word_overlap_plus_tags',
                'total_compared': len(notes) - 1
            }

            return similar_notes, similarity_info

        except Exception as e:
            # If reference file can't be read, return empty results
            return [], {'error': str(e), 'reference_file': reference_file}

    def _apply_query_filter(self, notes: List['ParsedNote'], query: str) -> List:
        """Apply text query filter with enhanced relevance scoring"""
        query_terms = query.lower().split()
        filtered_notes = []

        for note in notes:
            # Create searchable text with different weights for different sections
            content_text = note.content.lower()
            tags_text = ' '.join(note.tags).lower()
            frontmatter_text = json.dumps(note.frontmatter).lower()
            title_text = note.frontmatter.get('title', '').lower()

            # Calculate weighted relevance score
            content_score = sum(content_text.count(term) for term in query_terms) * 1.0
            title_score = sum(title_text.count(term) for term in query_terms) * 3.0  # Titles are very important
            tags_score = sum(tags_text.count(term) for term in query_terms) * 2.0   # Tags are important
            frontmatter_score = sum(frontmatter_text.count(term) for term in query_terms) * 0.5

            total_score = content_score + title_score + tags_score + frontmatter_score

            # Check if any terms are present
            all_text = f"{content_text} {tags_text} {frontmatter_text} {title_text}"
            if any(term in all_text for term in query_terms) and total_score > 0:
                # Boost score for exact phrase matches
                if len(query_terms) > 1 and query.lower() in all_text:
                    total_score *= 1.5

                filtered_notes.append({
                    'note': note,
                    'score': total_score
                })

        return filtered_notes

    def _extract_note_and_score(self, item):
        """Helper to extract note and score from either note object or dict format"""
        if isinstance(item, dict) and 'note' in item:
            return item['note'], item.get('score', 1.0)
        else:
            return item, 1.0

    def _apply_tag_filter(self, notes: List, tags_filter: str) -> List:
        """Filter notes by specific tags"""
        required_tags = [tag.strip().lower() for tag in tags_filter.split(',')]
        filtered_notes = []

        for item in notes:
            note, existing_score = self._extract_note_and_score(item)
            note_tags = [tag.lower() for tag in note.tags]

            # Check if note has all required tags (AND logic) or any required tags (OR logic)
            # Using OR logic for more flexible searching
            if any(req_tag in note_tags for req_tag in required_tags):
                tag_score = len([tag for tag in required_tags if tag in note_tags]) * 2
                filtered_notes.append({
                    'note': note,
                    'score': existing_score + tag_score  # Add to existing score
                })

        return filtered_notes

    def _apply_attendee_filter(self, notes: List, attendees_filter: str) -> List:
        """Filter notes by attendees"""
        required_attendees = [attendee.strip().lower() for attendee in attendees_filter.split(',')]
        filtered_notes = []

        for item in notes:
            note, existing_score = self._extract_note_and_score(item)
            note_attendees = [attendee.lower() for attendee in note.attendees]

            # Check if note has any of the required attendees
            matches = []
            for req_attendee in required_attendees:
                # Support partial name matching
                for note_attendee in note_attendees:
                    if req_attendee in note_attendee or note_attendee in req_attendee:
                        matches.append(req_attendee)
                        break

            if matches:
                attendee_score = len(matches) * 3  # High score for attendee matches
                filtered_notes.append({
                    'note': note,
                    'score': existing_score + attendee_score  # Add to existing score
                })

        return filtered_notes

    def _apply_category_filter(self, notes: List, category_filter: str) -> List:
        """Filter notes by PARA category"""
        # Map category names to category values
        category_mapping = {
            'projects': ['1-projects', '1_projects'],
            'areas': ['2-areas', '2_areas'],
            'resources': ['3-resources', '3_resources'],
            'archive': ['4-archive', '4_archive'],
            'inbox': ['inbox']
        }

        target_categories = category_mapping.get(category_filter.lower(), [category_filter])
        filtered_notes = []

        for item in notes:
            note, existing_score = self._extract_note_and_score(item)
            note_category = note.suggested_category.value if hasattr(note.suggested_category, 'value') else str(note.suggested_category)

            if any(target_cat in note_category.lower() for target_cat in target_categories):
                filtered_notes.append({
                    'note': note,
                    'score': existing_score + 1  # Add to existing score for category match
                })

        return filtered_notes

    def _apply_custom_date_filter(self, notes: List, date_from: str, date_to: str) -> List:
        """Filter notes by custom date range"""
        filtered_notes = []

        # Parse date boundaries
        try:
            from_date = datetime.datetime.strptime(date_from, '%Y-%m-%d').date() if date_from else None
            to_date = datetime.datetime.strptime(date_to, '%Y-%m-%d').date() if date_to else None
        except ValueError:
            # Return all notes with preserved scores if invalid date format
            return [{'note': self._extract_note_and_score(item)[0], 'score': self._extract_note_and_score(item)[1]} for item in notes]

        for item in notes:
            note, existing_score = self._extract_note_and_score(item)
            note_dates = []

            # Extract dates from note content and metadata
            if note.dates:
                for date_str in note.dates:
                    try:
                        if len(date_str.split()) > 1:  # Handle datetime strings
                            note_date = datetime.datetime.strptime(date_str.split()[0], '%Y-%m-%d').date()
                        else:
                            note_date = datetime.datetime.strptime(date_str, '%Y-%m-%d').date()
                        note_dates.append(note_date)
                    except ValueError:
                        continue

            # Also check file modification time as fallback
            try:
                file_date = datetime.date.fromtimestamp(Path(note.file_path).stat().st_mtime)
                note_dates.append(file_date)
            except:
                pass

            # Check if any date falls within range
            if note_dates:
                for note_date in note_dates:
                    within_range = True
                    if from_date and note_date < from_date:
                        within_range = False
                    if to_date and note_date > to_date:
                        within_range = False

                    if within_range:
                        filtered_notes.append({
                            'note': note,
                            'score': existing_score + 1  # Add to existing score for date match
                        })
                        break

        return filtered_notes

    def _sort_search_results(self, notes: List, query: str = None, similar_file: str = None) -> List:
        """Sort search results by relevance and recency"""
        if not notes:
            return notes

        # If notes are already scored (from filters), maintain that
        if isinstance(notes[0], dict) and 'score' in notes[0]:
            # Sort by score primarily, then by recency
            def sort_key(note_data):
                note = note_data['note']
                score = note_data.get('score', 0)

                # Add recency bonus - more recent files get slight boost
                try:
                    file_age_days = (datetime.datetime.now() - datetime.datetime.fromtimestamp(
                        Path(note.file_path).stat().st_mtime)).days
                    recency_bonus = max(0, (30 - file_age_days) / 30 * 0.2)  # Up to 0.2 bonus for recent files
                except:
                    recency_bonus = 0

                return score + recency_bonus

            notes.sort(key=sort_key, reverse=True)
        else:
            # For unscored notes, sort by file modification time
            def sort_key(note):
                try:
                    return Path(note.file_path).stat().st_mtime
                except:
                    return 0

            notes.sort(key=sort_key, reverse=True)
            # Convert to scored format for consistency
            notes = [{'note': note, 'score': 0} for note in notes]

        return notes

    def _extract_content_preview(self, note: 'ParsedNote', query: str = None) -> str:
        """Extract relevant content preview, highlighting search terms if query provided"""
        content = note.content
        preview_length = 200

        if query and query.strip():
            # Find the first occurrence of any query term for context
            query_terms = query.lower().split()
            content_lower = content.lower()

            best_position = 0
            for term in query_terms:
                position = content_lower.find(term)
                if position != -1:
                    # Start preview a bit before the term for context
                    best_position = max(0, position - 50)
                    break

            # Extract preview around the found term
            start = best_position
            end = min(len(content), start + preview_length)
            preview = content[start:end]

            # Clean up the preview
            if start > 0:
                preview = '...' + preview
            if end < len(content):
                preview = preview + '...'

        else:
            # Just take the beginning of the content
            preview = content[:preview_length]
            if len(content) > preview_length:
                preview += '...'

        # Clean up markdown formatting for readability
        preview = re.sub(r'#{1,6}\s+', '', preview)  # Remove headers
        preview = re.sub(r'\*\*(.+?)\*\*', r'\1', preview)  # Remove bold
        preview = re.sub(r'\*(.+?)\*', r'\1', preview)  # Remove italic
        preview = re.sub(r'\n+', ' ', preview)  # Replace newlines with spaces
        preview = re.sub(r'\s+', ' ', preview).strip()  # Normalize whitespace

        return preview

    def _perform_web_research(self, query: str) -> Dict[str, Any]:
        """Perform web search research on a topic using Claude Code's WebSearch tool"""
        try:
            # This method would normally use the WebSearch tool available in Claude Code
            # For now, return structured placeholder that Claude Code can recognize
            return {
                'query': query,
                'search_performed': True,
                'results_available': True,
                'instruction': f"Claude Code should use WebSearch tool to research: {query}",
                'suggested_searches': [
                    f"{query} latest developments",
                    f"{query} best practices",
                    f"{query} current trends"
                ]
            }
        except Exception as e:
            return {
                'query': query,
                'search_performed': False,
                'error': str(e),
                'instruction': f"Claude Code should use WebSearch tool to research: {query}"
            }

    def _collect_sources(self, web_research: Dict, related_notes: List) -> List[Dict[str, str]]:
        """Collect and format source attribution information"""
        sources = []

        # Add web research sources
        if web_research.get('search_performed'):
            sources.append({
                'type': 'web_search',
                'query': web_research.get('query', ''),
                'description': f"Web search results for: {web_research.get('query', '')}",
                'attribution': 'Research conducted via web search'
            })

        # Add related notes as sources
        for note in related_notes:
            sources.append({
                'type': 'note_reference',
                'file': note['file'],
                'path': note['path'],
                'description': f"Related note: {note['file']} (similarity: {note['similarity_score']})",
                'attribution': f"Cross-referenced from local note database"
            })

        return sources

    def _create_enhanced_content(self, original_note: 'ParsedNote', enhancements: List[Dict], preserve_original: bool = True) -> str:
        """Create enhanced content with clear separation between original and new content"""
        enhanced_content = []

        if preserve_original:
            # Start with original content
            enhanced_content.append("# Enhanced Note")
            enhanced_content.append("")
            enhanced_content.append("---")
            enhanced_content.append("")
            enhanced_content.append("## Original Content")
            enhanced_content.append("")
            enhanced_content.append(original_note.content)
            enhanced_content.append("")
            enhanced_content.append("---")
            enhanced_content.append("")
            enhanced_content.append("## Research Enhancements")
            enhanced_content.append("")
            enhanced_content.append(f"*The following content was added by Claude Code research on {datetime.date.today().strftime('%Y-%m-%d')}*")
            enhanced_content.append("")
        else:
            # Integrate enhancements into original content
            enhanced_content.append(original_note.content)
            enhanced_content.append("")
            enhanced_content.append("---")
            enhanced_content.append("")
            enhanced_content.append("## Additional Research")
            enhanced_content.append("")

        # Add each enhancement
        for i, enhancement in enumerate(enhancements, 1):
            if enhancement['type'] == 'web_search':
                enhanced_content.append(f"### Research Enhancement #{i}: Web Search")
                enhanced_content.append("")
                data = enhancement['data']
                enhanced_content.append(f"**Topic:** {data.get('query', 'N/A')}")
                enhanced_content.append("")
                enhanced_content.append(f"**Search Status:** {'Completed' if data.get('search_performed') else 'Pending'}")
                enhanced_content.append("")
                enhanced_content.append("**Claude Code Instructions:**")
                enhanced_content.append(f"- {data.get('instruction', 'No instruction')}")
                enhanced_content.append("")
                if data.get('suggested_searches'):
                    enhanced_content.append("**Suggested Search Queries:**")
                    for search in data['suggested_searches']:
                        enhanced_content.append(f"- {search}")
                    enhanced_content.append("")

            elif enhancement['type'] == 'cross_reference':
                enhanced_content.append(f"### Research Enhancement #{i}: Related Notes")
                enhanced_content.append("")
                related_notes = enhancement['data']
                enhanced_content.append(f"**Found {len(related_notes)} related notes in database:**")
                enhanced_content.append("")
                for note in related_notes:
                    enhanced_content.append(f"- **{note['file']}** (similarity: {note['similarity_score']})")
                    enhanced_content.append(f"  - Category: {note['category']}")
                    if note['tags']:
                        enhanced_content.append(f"  - Tags: {', '.join(note['tags'])}")
                    enhanced_content.append(f"  - Word count: {note['word_count']}")
                    enhanced_content.append("")

        # Add source attribution
        enhanced_content.append("---")
        enhanced_content.append("")
        enhanced_content.append("## Sources and Attribution")
        enhanced_content.append("")
        enhanced_content.append(f"**Enhanced by:** Claude Code Research System")
        enhanced_content.append(f"**Enhancement Date:** {datetime.date.today().strftime('%Y-%m-%d')}")
        enhanced_content.append("")
        enhanced_content.append("**Enhancement Types Applied:**")
        enhancement_types = [e['type'] for e in enhancements]
        for etype in set(enhancement_types):
            enhanced_content.append(f"- {etype.replace('_', ' ').title()}")
        enhanced_content.append("")

        return '\n'.join(enhanced_content)

    def _find_related_notes(self, note: 'ParsedNote', limit: int = 5) -> List[Dict[str, Any]]:
        """Find notes related to the current note using content similarity"""
        try:
            # Use existing find functionality to locate related notes
            all_notes = self.processor.batch_process_notes('.', '*.md')
            related_notes = []

            # Create search terms from the note
            search_terms = set()
            search_terms.update(note.tags)

            # Extract key terms from content (simple approach)
            content_words = note.content.lower().split()
            # Remove common words and keep meaningful terms
            meaningful_words = [w for w in content_words if len(w) > 4 and w.isalpha()]
            search_terms.update(meaningful_words[:20])  # Top 20 meaningful words

            # Score other notes for similarity
            for other_note in all_notes:
                if other_note.file_path == note.file_path:
                    continue  # Skip the same note

                # Calculate similarity score
                other_words = set(other_note.content.lower().split())
                other_tags = set(other_note.tags)

                # Content similarity (word overlap)
                word_overlap = len(search_terms & other_words)
                tag_overlap = len(set(note.tags) & other_tags)

                # Combined similarity score
                similarity_score = (word_overlap * 0.7) + (tag_overlap * 3.0)  # Tags weighted higher

                if similarity_score > 1.0:  # Minimum threshold
                    related_notes.append({
                        'file': Path(other_note.file_path).name,
                        'path': other_note.file_path,
                        'similarity_score': round(similarity_score, 2),
                        'word_overlap': word_overlap,
                        'tag_overlap': tag_overlap,
                        'tags': other_note.tags[:5],  # Show first 5 tags
                        'category': other_note.suggested_category.value,
                        'word_count': other_note.word_count
                    })

            # Sort by similarity score and return top results
            related_notes.sort(key=lambda x: x['similarity_score'], reverse=True)
            return related_notes[:limit]

        except Exception as e:
            return []

    def _collect_sources(self, web_research: Dict, related_notes: List) -> List[Dict[str, str]]:
        """Collect and format source attribution information"""
        sources = []

        # Add web research sources
        if web_research.get('search_performed'):
            sources.append({
                'type': 'web_search',
                'query': web_research.get('query', ''),
                'description': f"Web search results for: {web_research.get('query', '')}",
                'attribution': 'Research conducted via web search'
            })

        # Add related notes as sources
        for note in related_notes:
            sources.append({
                'type': 'note_reference',
                'file': note['file'],
                'path': note['path'],
                'description': f"Related note: {note['file']} (similarity: {note['similarity_score']})",
                'attribution': f"Cross-referenced from local note database"
            })

        return sources

    def _create_enhanced_content(self, original_note: 'ParsedNote', enhancements: List[Dict], preserve_original: bool = True) -> str:
        """Create enhanced content with clear separation between original and new content"""
        enhanced_content = []

        if preserve_original:
            # Start with original content
            enhanced_content.append("# Enhanced Note")
            enhanced_content.append("")
            enhanced_content.append("---")
            enhanced_content.append("")
            enhanced_content.append("## Original Content")
            enhanced_content.append("")
            enhanced_content.append(original_note.content)
            enhanced_content.append("")
            enhanced_content.append("---")
            enhanced_content.append("")
            enhanced_content.append("## Research Enhancements")
            enhanced_content.append("")
            enhanced_content.append(f"*The following content was added by Claude Code research on {datetime.date.today().strftime('%Y-%m-%d')}*")
            enhanced_content.append("")
        else:
            # Integrate enhancements into original content
            enhanced_content.append(original_note.content)
            enhanced_content.append("")
            enhanced_content.append("---")
            enhanced_content.append("")
            enhanced_content.append("## Additional Research")
            enhanced_content.append("")

        # Add each enhancement
        for i, enhancement in enumerate(enhancements, 1):
            if enhancement['type'] == 'web_search':
                enhanced_content.append(f"### Research Enhancement #{i}: Web Search")
                enhanced_content.append("")
                data = enhancement['data']
                enhanced_content.append(f"**Topic:** {data.get('query', 'N/A')}")
                enhanced_content.append("")
                enhanced_content.append(f"**Search Status:** {'Completed' if data.get('search_performed') else 'Pending'}")
                enhanced_content.append("")
                enhanced_content.append("**Claude Code Instructions:**")
                enhanced_content.append(f"- {data.get('instruction', 'No instruction')}")
                enhanced_content.append("")
                if data.get('suggested_searches'):
                    enhanced_content.append("**Suggested Search Queries:**")
                    for search in data['suggested_searches']:
                        enhanced_content.append(f"- {search}")
                    enhanced_content.append("")

            elif enhancement['type'] == 'cross_reference':
                enhanced_content.append(f"### Research Enhancement #{i}: Related Notes")
                enhanced_content.append("")
                related_notes = enhancement['data']
                enhanced_content.append(f"**Found {len(related_notes)} related notes in database:**")
                enhanced_content.append("")
                for note in related_notes:
                    enhanced_content.append(f"- **{note['file']}** (similarity: {note['similarity_score']})")
                    enhanced_content.append(f"  - Category: {note['category']}")
                    if note['tags']:
                        enhanced_content.append(f"  - Tags: {', '.join(note['tags'])}")
                    enhanced_content.append(f"  - Word count: {note['word_count']}")
                    enhanced_content.append("")

        # Add source attribution
        enhanced_content.append("---")
        enhanced_content.append("")
        enhanced_content.append("## Sources and Attribution")
        enhanced_content.append("")
        enhanced_content.append(f"**Enhanced by:** Claude Code Research System")
        enhanced_content.append(f"**Enhancement Date:** {datetime.date.today().strftime('%Y-%m-%d')}")
        enhanced_content.append("")
        enhanced_content.append("**Enhancement Types Applied:**")
        enhancement_types = [e['type'] for e in enhancements]
        for etype in set(enhancement_types):
            enhanced_content.append(f"- {etype.replace('_', ' ').title()}")
        enhanced_content.append("")

        return '\n'.join(enhanced_content)

    def _apply_similarity_filter(self, notes: List['ParsedNote'], reference_file: str) -> tuple:
        """Find notes similar to the reference file using content similarity"""
        try:
            # Parse the reference file
            reference_note = self.processor.parse_note(reference_file)
            reference_words = set(reference_note.content.lower().split())

            # Remove common words for better similarity matching
            common_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could', 'should', 'this', 'that', 'these', 'those'}
            reference_words -= common_words

            similar_notes = []
            for note in notes:
                if note.file_path == reference_file:
                    continue  # Skip the reference file itself

                note_words = set(note.content.lower().split()) - common_words

                # Calculate word overlap similarity (Jaccard index)
                if len(reference_words) > 0 and len(note_words) > 0:
                    intersection = len(reference_words & note_words)
                    union = len(reference_words | note_words)
                    similarity = intersection / union if union > 0 else 0

                    # Also consider tag similarity
                    ref_tags = set(reference_note.tags)
                    note_tags = set(note.tags)
                    if ref_tags and note_tags:
                        tag_similarity = len(ref_tags & note_tags) / len(ref_tags | note_tags)
                        similarity = (similarity * 0.8) + (tag_similarity * 0.2)  # Weight content higher

                    if similarity > 0.05:  # Only include notes with some similarity
                        similar_notes.append({
                            'note': note,
                            'similarity': similarity,
                            'score': similarity * 100  # For sorting compatibility
                        })

            # Sort by similarity
            similar_notes.sort(key=lambda x: x['similarity'], reverse=True)

            similarity_info = {
                'reference_file': reference_file,
                'method': 'word_overlap_plus_tags',
                'total_compared': len(notes) - 1
            }

            return similar_notes, similarity_info

        except Exception as e:
            # If reference file can't be read, return empty results
            return [], {'error': str(e), 'reference_file': reference_file}

    def _apply_query_filter(self, notes: List['ParsedNote'], query: str) -> List:
        """Apply text query filter with enhanced relevance scoring"""
        query_terms = query.lower().split()
        filtered_notes = []

        for note in notes:
            # Create searchable text with different weights for different sections
            content_text = note.content.lower()
            tags_text = ' '.join(note.tags).lower()
            frontmatter_text = json.dumps(note.frontmatter).lower()
            title_text = note.frontmatter.get('title', '').lower()

            # Calculate weighted relevance score
            content_score = sum(content_text.count(term) for term in query_terms) * 1.0
            title_score = sum(title_text.count(term) for term in query_terms) * 3.0  # Titles are very important
            tags_score = sum(tags_text.count(term) for term in query_terms) * 2.0   # Tags are important
            frontmatter_score = sum(frontmatter_text.count(term) for term in query_terms) * 0.5

            total_score = content_score + title_score + tags_score + frontmatter_score

            # Check if any terms are present
            all_text = f"{content_text} {tags_text} {frontmatter_text} {title_text}"
            if any(term in all_text for term in query_terms) and total_score > 0:
                # Boost score for exact phrase matches
                if len(query_terms) > 1 and query.lower() in all_text:
                    total_score *= 1.5

                filtered_notes.append({
                    'note': note,
                    'score': total_score
                })

        return filtered_notes

    def _extract_note_and_score(self, item):
        """Helper to extract note and score from either note object or dict format"""
        if isinstance(item, dict) and 'note' in item:
            return item['note'], item.get('score', 1.0)
        else:
            return item, 1.0

    def _apply_tag_filter(self, notes: List, tags_filter: str) -> List:
        """Filter notes by specific tags"""
        required_tags = [tag.strip().lower() for tag in tags_filter.split(',')]
        filtered_notes = []

        for item in notes:
            note, existing_score = self._extract_note_and_score(item)
            note_tags = [tag.lower() for tag in note.tags]

            # Check if note has all required tags (AND logic) or any required tags (OR logic)
            # Using OR logic for more flexible searching
            if any(req_tag in note_tags for req_tag in required_tags):
                tag_score = len([tag for tag in required_tags if tag in note_tags]) * 2
                filtered_notes.append({
                    'note': note,
                    'score': existing_score + tag_score  # Add to existing score
                })

        return filtered_notes

    def _apply_attendee_filter(self, notes: List, attendees_filter: str) -> List:
        """Filter notes by attendees"""
        required_attendees = [attendee.strip().lower() for attendee in attendees_filter.split(',')]
        filtered_notes = []

        for item in notes:
            note, existing_score = self._extract_note_and_score(item)
            note_attendees = [attendee.lower() for attendee in note.attendees]

            # Check if note has any of the required attendees
            matches = []
            for req_attendee in required_attendees:
                # Support partial name matching
                for note_attendee in note_attendees:
                    if req_attendee in note_attendee or note_attendee in req_attendee:
                        matches.append(req_attendee)
                        break

            if matches:
                attendee_score = len(matches) * 3  # High score for attendee matches
                filtered_notes.append({
                    'note': note,
                    'score': existing_score + attendee_score  # Add to existing score
                })

        return filtered_notes

    def _apply_category_filter(self, notes: List, category_filter: str) -> List:
        """Filter notes by PARA category"""
        # Map category names to category values
        category_mapping = {
            'projects': ['1-projects', '1_projects'],
            'areas': ['2-areas', '2_areas'],
            'resources': ['3-resources', '3_resources'],
            'archive': ['4-archive', '4_archive'],
            'inbox': ['inbox']
        }

        target_categories = category_mapping.get(category_filter.lower(), [category_filter])
        filtered_notes = []

        for item in notes:
            note, existing_score = self._extract_note_and_score(item)
            note_category = note.suggested_category.value if hasattr(note.suggested_category, 'value') else str(note.suggested_category)

            if any(target_cat in note_category.lower() for target_cat in target_categories):
                filtered_notes.append({
                    'note': note,
                    'score': existing_score + 1  # Add to existing score for category match
                })

        return filtered_notes

    def _apply_custom_date_filter(self, notes: List, date_from: str, date_to: str) -> List:
        """Filter notes by custom date range"""
        filtered_notes = []

        # Parse date boundaries
        try:
            from_date = datetime.datetime.strptime(date_from, '%Y-%m-%d').date() if date_from else None
            to_date = datetime.datetime.strptime(date_to, '%Y-%m-%d').date() if date_to else None
        except ValueError:
            # Return all notes with preserved scores if invalid date format
            return [{'note': self._extract_note_and_score(item)[0], 'score': self._extract_note_and_score(item)[1]} for item in notes]

        for item in notes:
            note, existing_score = self._extract_note_and_score(item)
            note_dates = []

            # Extract dates from note content and metadata
            if note.dates:
                for date_str in note.dates:
                    try:
                        if len(date_str.split()) > 1:  # Handle datetime strings
                            note_date = datetime.datetime.strptime(date_str.split()[0], '%Y-%m-%d').date()
                        else:
                            note_date = datetime.datetime.strptime(date_str, '%Y-%m-%d').date()
                        note_dates.append(note_date)
                    except ValueError:
                        continue

            # Also check file modification time as fallback
            try:
                file_date = datetime.date.fromtimestamp(Path(note.file_path).stat().st_mtime)
                note_dates.append(file_date)
            except:
                pass

            # Check if any date falls within range
            if note_dates:
                for note_date in note_dates:
                    within_range = True
                    if from_date and note_date < from_date:
                        within_range = False
                    if to_date and note_date > to_date:
                        within_range = False

                    if within_range:
                        filtered_notes.append({
                            'note': note,
                            'score': existing_score + 1  # Add to existing score for date match
                        })
                        break

        return filtered_notes

    def _sort_search_results(self, notes: List, query: str = None, similar_file: str = None) -> List:
        """Sort search results by relevance and recency"""
        if not notes:
            return notes

        # If notes are already scored (from filters), maintain that
        if isinstance(notes[0], dict) and 'score' in notes[0]:
            # Sort by score primarily, then by recency
            def sort_key(note_data):
                note = note_data['note']
                score = note_data.get('score', 0)

                # Add recency bonus - more recent files get slight boost
                try:
                    file_age_days = (datetime.datetime.now() - datetime.datetime.fromtimestamp(
                        Path(note.file_path).stat().st_mtime)).days
                    recency_bonus = max(0, (30 - file_age_days) / 30 * 0.2)  # Up to 0.2 bonus for recent files
                except:
                    recency_bonus = 0

                return score + recency_bonus

            notes.sort(key=sort_key, reverse=True)
        else:
            # For unscored notes, sort by file modification time
            def sort_key(note):
                try:
                    return Path(note.file_path).stat().st_mtime
                except:
                    return 0

            notes.sort(key=sort_key, reverse=True)
            # Convert to scored format for consistency
            notes = [{'note': note, 'score': 0} for note in notes]

        return notes

    def _extract_content_preview(self, note: 'ParsedNote', query: str = None) -> str:
        """Extract relevant content preview, highlighting search terms if query provided"""
        content = note.content
        preview_length = 200

        if query and query.strip():
            # Find the first occurrence of any query term for context
            query_terms = query.lower().split()
            content_lower = content.lower()

            best_position = 0
            for term in query_terms:
                position = content_lower.find(term)
                if position != -1:
                    # Start preview a bit before the term for context
                    best_position = max(0, position - 50)
                    break

            # Extract preview around the found term
            start = best_position
            end = min(len(content), start + preview_length)
            preview = content[start:end]

            # Clean up the preview
            if start > 0:
                preview = '...' + preview
            if end < len(content):
                preview = preview + '...'

        else:
            # Just take the beginning of the content
            preview = content[:preview_length]
            if len(content) > preview_length:
                preview += '...'

        # Clean up markdown formatting for readability
        preview = re.sub(r'#{1,6}\s+', '', preview)  # Remove headers
        preview = re.sub(r'\*\*(.+?)\*\*', r'\1', preview)  # Remove bold
        preview = re.sub(r'\*(.+?)\*', r'\1', preview)  # Remove italic
        preview = re.sub(r'\n+', ' ', preview)  # Replace newlines with spaces
        preview = re.sub(r'\s+', ' ', preview).strip()  # Normalize whitespace

        return preview

    def _filter_by_date_range(self, notes: List, date_range: str) -> List:
        """Filter notes by date range"""
        if date_range == 'today':
            target_date = datetime.date.today().strftime('%Y-%m-%d')
        elif date_range == 'yesterday':
            target_date = (datetime.date.today() - datetime.timedelta(days=1)).strftime('%Y-%m-%d')
        elif date_range == 'last-week':
            target_date = (datetime.date.today() - datetime.timedelta(days=7)).strftime('%Y-%m-%d')
        elif date_range == 'last-month':
            target_date = (datetime.date.today() - datetime.timedelta(days=30)).strftime('%Y-%m-%d')
        else:
            # Unknown date range, return all notes with preserved scores
            return [{'note': self._extract_note_and_score(item)[0], 'score': self._extract_note_and_score(item)[1]} for item in notes]

        filtered = []
        for item in notes:
            note, existing_score = self._extract_note_and_score(item)
            # Check if any date in the note matches our criteria
            if any(date >= target_date for date in note.dates):
                filtered.append({'note': note, 'score': existing_score + 1})
            # Also check file modification time as fallback
            elif Path(note.file_path).stat().st_mtime > (datetime.datetime.now() - datetime.timedelta(days=7)).timestamp():
                filtered.append({'note': note, 'score': existing_score + 1})

        return filtered

def main():
    """Main CLI interface"""
    parser = argparse.ArgumentParser(
        description="Unified PARA Notes Interface for Claude Code",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  /notes capture --template meeting --topic "Q4 Planning" --attendees "john,sarah"
  /notes process-inbox --auto-suggest --batch 5
  /notes process-inbox --list
  /notes process-inbox --interactive --batch 3
  /notes review-note --file "inbox/meeting-notes.md"
  /notes review-note --file "inbox/meeting-notes.md" --category projects
  /notes research --file "project-kickoff.md" --expand-topics
  /notes find --query "budget concerns" --date-range last-month
  /notes follow-up --status overdue
  /notes prep --topic "budget review" --attendees "cfo,manager"

Natural language support:
  /notes capture about "sprint planning" with john,sarah using meeting template
  /notes find about "api design" from last-week
        """)

    # Add JSON output option
    parser.add_argument('--json', action='store_true', help='Output results as JSON')
    parser.add_argument('--format', choices=['json', 'text'], default='json', help='Output format (default: json)')

    subparsers = parser.add_subparsers(dest='command', help='Available commands')

    # Capture command
    capture_parser = subparsers.add_parser('capture', help='Create new notes from templates')
    capture_parser.add_argument('--template', help='Template to use')
    capture_parser.add_argument('--topic', help='Note topic/title')
    capture_parser.add_argument('--attendees', help='Comma-separated attendees list')
    capture_parser.add_argument('--date', help='Date (YYYY-MM-DD)')
    capture_parser.add_argument('--output', '-o', help='Output file path')
    capture_parser.add_argument('--var', action='append', help='Custom variable (key=value)')
    capture_parser.add_argument('natural', nargs='*', help='Natural language input')

    # Process inbox command
    process_parser = subparsers.add_parser('process-inbox', help='Process inbox notes')
    process_parser.add_argument('--directory', default='inbox', help='Directory to process')
    process_parser.add_argument('--pattern', default='*.md', help='File pattern')
    process_parser.add_argument('--auto-suggest', action='store_true', help='Auto-suggest PARA categories')
    process_parser.add_argument('--batch', type=int, help='Limit number of notes to process')
    process_parser.add_argument('--list', action='store_true', help='List notes without processing')
    process_parser.add_argument('--interactive', action='store_true', help='Interactive review mode for Claude Code')

    # Review note command
    review_parser = subparsers.add_parser('review-note', help='Review and process individual notes')
    review_parser.add_argument('--file', required=True, help='Note file to review')
    review_parser.add_argument('--category', choices=['projects', 'areas', 'resources', 'archive'], help='Move to PARA category')
    review_parser.add_argument('--full-content', action='store_true', help='Include full content in response')
    review_parser.add_argument('--undo-move', action='store_true', help='Undo previous move operation')

    # Research command
    research_parser = subparsers.add_parser('research', help='Research and analyze notes')
    research_parser.add_argument('--file', help='Note file to analyze')
    research_parser.add_argument('--expand-topics', action='store_true', help='Find related topics')
    research_parser.add_argument('--web-search', action='store_true', help='Enhance with web search results')
    research_parser.add_argument('--cross-reference', action='store_true', help='Find related notes in database')
    research_parser.add_argument('--query', help='Specific topic to research (overrides auto-detection)')
    research_parser.add_argument('--limit', type=int, default=5, help='Maximum related notes to find')
    research_parser.add_argument('--graceful', action='store_true', help='Handle malformed notes gracefully')

    # Enhance command
    enhance_parser = subparsers.add_parser('enhance', help='Add context and background to notes')
    enhance_parser.add_argument('--file', required=True, help='Note file to enhance')
    enhance_parser.add_argument('--topic', help='Specific topic to enhance (overrides auto-detection)')
    enhance_parser.add_argument('--web-search', action='store_true', help='Add web search context')
    enhance_parser.add_argument('--cross-reference', action='store_true', help='Add related notes context')
    enhance_parser.add_argument('--preserve-original', action='store_true', default=True, help='Preserve original content clearly separated')
    enhance_parser.add_argument('--output', help='Output file path (default: updates original)')

    # Connect command
    connect_parser = subparsers.add_parser('connect', help='Find connections between notes')
    connect_parser.add_argument('--file', help='Note file to find connections for')
    connect_parser.add_argument('--query', help='Topic or theme to find connections about')
    connect_parser.add_argument('--directory', default='.', help='Directory to search for connections')
    connect_parser.add_argument('--similarity-threshold', type=float, default=0.1, help='Minimum similarity score')
    connect_parser.add_argument('--limit', type=int, default=10, help='Maximum connections to find')

    # Find command
    find_parser = subparsers.add_parser('find', help='Search for notes')
    find_parser.add_argument('--query', help='Search query')
    find_parser.add_argument('--tags', help='Filter by comma-separated tags')
    find_parser.add_argument('--attendees', help='Filter by comma-separated attendees')
    find_parser.add_argument('--date-range', choices=['today', 'yesterday', 'last-week', 'last-month'], help='Date range filter (preset)')
    find_parser.add_argument('--date-from', help='Custom start date (YYYY-MM-DD)')
    find_parser.add_argument('--date-to', help='Custom end date (YYYY-MM-DD)')
    find_parser.add_argument('--similar', help='Find notes similar to specified file')
    find_parser.add_argument('--preview', action='store_true', help='Show content preview')
    find_parser.add_argument('--category', choices=['projects', 'areas', 'resources', 'archive', 'inbox'], help='Filter by PARA category')
    find_parser.add_argument('--directory', default='.', help='Directory to search')
    find_parser.add_argument('--limit', type=int, default=10, help='Maximum results')

    # Follow-up command
    followup_parser = subparsers.add_parser('follow-up', help='Manage action items')
    followup_parser.add_argument('--status', choices=['all', 'overdue', 'pending', 'completed'], default='all')
    followup_parser.add_argument('--assignee', help='Filter by assignee')
    followup_parser.add_argument('--directory', default='.', help='Directory to search')

    # Prep command
    prep_parser = subparsers.add_parser('prep', help='Prepare for meetings')
    prep_parser.add_argument('--topic', help='Meeting topic')
    prep_parser.add_argument('--attendees', help='Comma-separated attendees')
    prep_parser.add_argument('--output', help='Output file path')

    # Gather context command
    gather_context_parser = subparsers.add_parser('gather-context', help='Retrieve and synthesize relevant historical information')
    gather_context_parser.add_argument('--topic', help='Topic to gather context for')
    gather_context_parser.add_argument('--attendees', help='Comma-separated attendees to gather context for')
    gather_context_parser.add_argument('--days-back', type=int, default=90, help='Days to look back for context')
    gather_context_parser.add_argument('--max-results', type=int, default=10, help='Maximum number of results to return')

    # Check actions command
    check_actions_parser = subparsers.add_parser('check-actions', help='Identify outstanding action items related to meeting participants/topics')
    check_actions_parser.add_argument('--attendees', help='Comma-separated attendees to check actions for')
    check_actions_parser.add_argument('--topic', help='Topic to check actions for')
    check_actions_parser.add_argument('--status', choices=['all', 'overdue', 'pending', 'completed'], default='pending', help='Action status to check')

    # Suggest agenda command
    suggest_agenda_parser = subparsers.add_parser('suggest-agenda', help='Propose agenda items based on historical meeting patterns and outstanding items')
    suggest_agenda_parser.add_argument('--attendees', help='Comma-separated attendees')
    suggest_agenda_parser.add_argument('--topic', help='Meeting topic')
    suggest_agenda_parser.add_argument('--meeting-type', choices=['1-on-1', 'team-meeting', 'project-review', 'general'], default='general', help='Type of meeting')

    # List templates command
    list_parser = subparsers.add_parser('list-templates', help='List available templates')

    # Parse arguments
    args = parser.parse_args()

    if not args.command:
        parser.print_help()
        return

    # Create interface and execute command
    interface = NotesCommandInterface()

    try:
        # Route to appropriate command handler
        command_methods = {
            'capture': interface.cmd_capture,
            'process-inbox': interface.cmd_process_inbox,
            'review-note': interface.cmd_review_note,
            'research': interface.cmd_research,
            'enhance': interface.cmd_enhance,
            'connect': interface.cmd_connect,
            'find': interface.cmd_find,
            'follow-up': interface.cmd_follow_up,
            'prep': interface.cmd_prep,
            'gather-context': interface.cmd_gather_context,
            'check-actions': interface.cmd_check_actions,
            'suggest-agenda': interface.cmd_suggest_agenda,
            'list-templates': interface.cmd_list_templates,
        }

        if args.command in command_methods:
            result = command_methods[args.command](args)
        else:
            result = interface.format_error_result(
                args.command,
                f"Unknown command: {args.command}",
                suggestions=list(command_methods.keys())
            )

        # Output result
        if args.format == 'json' or args.json:
            print(json.dumps(asdict(result), indent=2, default=str))
        else:
            # Text format for debugging
            if result.success:
                print(f"✅ {result.message}")
                if result.data:
                    for key, value in result.data.items():
                        print(f"   {key}: {value}")
            else:
                print(f"❌ {result.message}")
                if result.error_details:
                    print(f"   Error: {result.error_details}")

            if result.suggestions:
                print("\nSuggestions:")
                for suggestion in result.suggestions:
                    if suggestion:
                        print(f"   • {suggestion}")

    except Exception as e:
        error_result = interface.format_error_result(
            args.command or 'unknown',
            f"Unexpected error: {str(e)}",
            str(e)
        )

        if args.format == 'json' or args.json:
            print(json.dumps(asdict(error_result), indent=2, default=str))
        else:
            print(f"❌ {error_result.message}")
            print(f"   Error: {error_result.error_details}")

if __name__ == '__main__':
    main()